\documentclass[11pt,a4paper]{article}
\usepackage{acl2017}
\usepackage{times}
% \usepackage{multirow}
\usepackage{url}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{color}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage[utf8]{vietnam}
\usepackage{titlesec}

\newcommand\version{1.1.12}

\aclfinalcopy % Uncomment this line for the final submission

%\setlength\titlebox{5cm}

\title{Báo cáo kỹ thuật\\ Xây dựng hệ thống tách từ tiếng Việt \\ underthesea v\version}

\author{
Vu Anh\\
underthesea\\
anhv.ict91@gmail.com
}
\date{}

% margins for abstract
\renewenvironment{abstract}%
{\centerline{\large\bf Tóm tắt}%
\begin{list}{}%
{\setlength{\rightmargin}{0.6cm}%
\setlength{\leftmargin}{0.6cm}}%
\item[]\ignorespaces}%
{\unskip\end{list}}




\begin{document}



\maketitle
\begin{abstract}

Trong báo cáo này, chúng tôi mô tả chương trình tách từ tiếng Việt, được tích hợp trong phiên bản underthesea phiên bản \version.
Các công trình nghiên cứu trước đã rất thành công trong bài toán tách từ, chúng tôi muốn nghiên cứu lại sự hiệu quả của phương pháp Conditional Random Fields trong bài toán này. Sau đó xây dựng hệ thống tách từ hoàn chỉnh.
Mã nguồn của chương trình được open source tại \href{https://github.com/undertheseanlp/word_tokenize}{github}.

\end{abstract}

\section{Giới thiệu}

Tách từ là một bài toán quan trọng trong việc xử lý rất nhiều ngôn ngữ. Đối với tiếng Việt, nhiệm vụ này khá khó khăn do một từ tiếng Việt thường gồm nhiều tiếng ghép lại. Ví dụ như từ \textit{giáo viên} gồm hai tiếng \textit{giáo} và \textit{viên}.

Trong nghiên cứu này, chúng tôi xây dựng chương trình dựa trên giải thuật Conditional Random Fields trên bộ dữ liệu VLSP 2013.

\section{Các công trình liên quan}

Bài toán tách từ tiếng Việt đã được nghiên cứu từ khá lâu. \citet{Nguyen2006VietnameseWS} sử dụng CRFs và SVM trên dữ liệu khoảng 7800 câu. \citet{huyen2008hybrid} sử dụng các phương pháp kết hợp. \citet{7800279} sử dụng logistic regression trên 78000 câu.

\section{Mô tả hệ thống}

\subsection{Hệ thống tách từ}

Hệ thống tách từ trong underthesea được chia làm hai bước. Bước đầu tiên là bước tiền xử lý. Trong bước này, văn bản được tách câu và tokenize sử dụng regular expression. Bước thứ hai, các từ được biểu diễn dưới dạng một bài toán gán nhãn chuỗi.

\subsection{Thuật toán Conditional Random Fields}

Thuật toán Conditional Random Fields (CRFs) ~\cite{Lafferty:2001:CRF:645530.655813} được sử dụng đã tính toán xác suất của chuỗi đầu ra cho bởi chuỗi đầu vào. Xác suất của chuỗi trạng thái $S = \langle s_1, s_2,..., s_T \rangle$ cho bởi quan sát $O = \langle o_1, o_2, ..., o_T \rangle$ được tính bởi công thức:

$$P(S|O) = \frac{1}{Z_o} \exp( \sum_{t=1}^{T} \sum_{k} \lambda_k x f_k (s_{t-1},s_t,o,t) )$$

trong đó, $f_k (s_{t-1},s_t,o,t)$ làm một hàm đặc trưng ứng với trọng số $\lambda_k$, được học thông qua quá trình huấn luyện.

\subsection{Features}

Các đặc trưng được đề xuất

\begin{center}
\begin{tabular}{ |c|c| }
 \hline
 features & description \\
 \hline
 T[-2], T[-1], T[0], T[1], T[2] & unigram  \\
 T[-2,-1], T[-1,0], T[0,1], T[1,2] & bigram  \\
 T[-2,0], T[-1,1], T[0,2] & trigram \\
 T[-1].isdigit, T[0].isdigit, T[1].isdigit & digit \\
 \hline
\end{tabular}
\end{center}

\section{Thực nghiệm}

\subsection{Dữ liệu}

Để so sánh độ chính xác của chương trình. Chúng tôi sử dụng bộ dữ liệu đã được sử dụng trong \citet{DBLP:conf/lrec/NguyenNVDJ18} và \citet{7800279}. Dữ liệu huấn luyện gồm 75 nghìn câu được lấy từ dữ liệu huấn luyện của bài toán tách từ trong VLSP 2013. Dữ liệu kiểm thử gồm 2120 câu lấy từ bộ dữ liệu gán nhãn từ loại trong VLSP 2013.

\subsection{Chỉ số đánh giá}

Chúng tôi sử dụng precision, recall và f1 làm các chỉ số đánh giá.


$$F_1 = \frac{2PR}{P + R}$$

trong đó $P$ (Precision), và $R$ (Recall) được định nghĩa như sau:

$$P = \frac{\mathit{NE}_{\mathrm{true}}}{\mathit{NE}_{\mathrm{sys}}}$$

$$R = \frac{\mathit{NE}_{\mathrm{true}}}{\mathit{NE}_{\mathrm{ref}}}$$

với

$\mathit{NE}_{\mathrm{true}}$: The number of NEs in gold data

$\mathit{NE}_{\mathrm{sys}}$: The number of NEs in recognizing system

$\mathit{NE}_{\mathrm{ref}}$: The number of NEs which is correctly recognized by the system

\subsection{Kết quả}

We conduct our experiment on VLSP 2013 dataset, the result show we achieve 97.3\%
\newline

\begin{tabular}{ |l|l|l| }
 \hline
 system & features & result \\
 \hline
 s1 & ngram & 96.42\% \\
 s2 & s1 + lower & 96.45\% \\
 s3 & s2 + isdigit & 96.54\% \\
 s4 & s3 + istitle & 96.45\% \\
 s5 & s4 + unigram is in dict & 96.45\% \\
 s6 & s5 + bigram is in dict & 97.34\% \\
 sn & full & 97.31\% \\
 \hline
\end{tabular}

\section{Kết luận}

Trong báo cáo này, chúng tôi đã mô tả hệ thống tách từ được tích hợp trong underthesea phiên bản \version.

\bibliography{technique_report}
\bibliographystyle{acl_natbib}

\end{document}
